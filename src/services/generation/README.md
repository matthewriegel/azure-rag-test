# Generation Service

LLM-based answer generation service that uses Azure OpenAI to produce structured JSON responses with answers, data paths, explanations, and self-confidence scores.

## Architecture

```mermaid
graph LR
    A[Search Results] --> B[Build Context]
    B --> C[Create Prompt]
    C --> D[Azure OpenAI]
    D --> E[Parse JSON Response]
    E --> F[Return Answer Object]
```

## Generation Flow

```mermaid
sequenceDiagram
    participant R as RAG Service
    participant G as Generation Service
    participant O as OpenAI

    R->>G: generateAnswer(query, results)
    G->>G: Build context from search results
    G->>G: Create structured prompt
    G->>O: getChatCompletion(messages)
    O-->>G: JSON response
    G->>G: Parse & validate
    G-->>R: {answer, dataPath, confidence, explanation}
```

## Prompt Structure

```typescript
const systemPrompt = `You are a precise data extraction assistant.
Extract the answer from the provided context.
Return JSON: { answer, dataPath, confidence, explanation }`;

const userPrompt = `Question: ${query}
Context: ${searchResults}`;
```

## Response Format

```json
{
  "answer": "john.doe@example.com",
  "dataPath": ["contact.email"],
  "confidence": 0.95,
  "explanation": "Found exact email field in contact information"
}
```

## File Pointers

- **Service**: `src/services/generation/generationService.ts`
- **API caller**: Uses `lib/azure/openaiClient.ts`

## Example Usage

```typescript
import { generateAnswer } from './services/generation';

const result = await generateAnswer({
  query: 'What is the customer phone?',
  searchResults: retrievedChunks
});

console.log(result.answer); // "555-1234"
```

---

**Last updated**: 2026-02-01T15:42:00Z  
**Author**: Generated by Copilot action prompt; review recommended
